# Support RAG Agent

Простой каркасный ИИ-агент поддержки с RAG на базе smolagents.



## Описание

Агент отвечает(текстом) на текстовые вопросы пользователей строго на основе локальной базы знаний (Markdown-файлы в knowledge_base/raw/).


*В качестве примера документов используется набор инструкций выдуманного сервиса **RideWay**, напоминающего небезызвестный сервис Blablacar.*



## Используются технологии:

* **smolagents** - агентский фрейворк

* **ChromaDB** - векторное хранилище

* **intfloat/multilingual-e5-large-instruct** - модель для построения базы знаний-эмбеддингов (локально) 

* **gemini-2.0-flash** - модель рассуждений агента (через OpenAI-совместимый эндпоинт)





## Структура проекта

Полностью автономен после индексации — работает оффлайн (кроме вызовов Gemini).

```
.
├── main.py                     # Запуск агента (CLI)
├── rebuild_index.py            # Перестроение базы знаний
├── knowledge_base/
│   ├── raw/                    # Markdown-документы с информацией (FAQ, тарифы, инструкции)
│   └── vector_store/
│       ├── chroma_repo.py      # Работа с Chroma
│       └── protocol.py         # Интерфейс репозитория
├── tools/
│   └── rag_tool.py             # Инструмент retrieve_knowledge
├── .env                        # GEMINI_API_KEY
└── requirements.txt
```

## Установка

```
python3 -m venv venv
source venv/bin/activate
pip install -r requirements.txt
```

## Настройка

1. Создайте файл .env в корне проекта и укажите токен для рассуждающей LLM.
2. Замените, файлы инструкций в ```knowledge_base/raw/```.
3. Проиндексируйте файлы инструкций(создайте эмбединги в векторном хранилище):
```
python3 rebuild_index.py
```
4. Запустите приложение:
```
python3 main.py
```